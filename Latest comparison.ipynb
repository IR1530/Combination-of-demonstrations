{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77221646-af61-4a28-9d33-8ac7317a1374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad68915-bd8f-4f1b-b53f-ed5e42d6806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Dataset in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from Dataset) (1.4.53)\n",
      "Requirement already satisfied: alembic>=0.6.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from Dataset) (1.13.2)\n",
      "Requirement already satisfied: banal>=1.0.1 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from Dataset) (1.0.6)\n",
      "Requirement already satisfied: Mako in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from alembic>=0.6.2->Dataset) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from alembic>=0.6.2->Dataset) (4.11.0)\n",
      "Requirement already satisfied: importlib-metadata in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from alembic>=0.6.2->Dataset) (7.0.1)\n",
      "Requirement already satisfied: importlib-resources in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from alembic>=0.6.2->Dataset) (6.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from sqlalchemy<2.0.0,>=1.3.2->Dataset) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from importlib-metadata->alembic>=0.6.2->Dataset) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /nfs/primary/conda-envs/ishan/lib/python3.8/site-packages (from Mako->alembic>=0.6.2->Dataset) (2.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93393669-70b2-4180-9fec-9e37af541140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11c5528eb544eefae4d24de8a74967e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set:  6920\n",
      "Length of test set 1821\n",
      "Train example at 0th index:  {\n",
      "  \"guid\": \"train.tsv-0\",\n",
      "  \"label\": 1,\n",
      "  \"text_a\": \"a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films\",\n",
      "  \"text_b\": \"\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/183 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 183/183 [1:18:54<00:00, 25.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5721    0.6352    0.6020      9120\n",
      "           1     0.5885    0.5234    0.5541      9090\n",
      "\n",
      "    accuracy                         0.5794     18210\n",
      "   macro avg     0.5803    0.5793    0.5780     18210\n",
      "weighted avg     0.5803    0.5794    0.5781     18210\n",
      "\n",
      "Two-shot Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9224    0.7924    0.8525     41040\n",
      "           1     0.8175    0.9332    0.8715     40905\n",
      "\n",
      "    accuracy                         0.8627     81945\n",
      "   macro avg     0.8700    0.8628    0.8620     81945\n",
      "weighted avg     0.8701    0.8627    0.8620     81945\n",
      "\n",
      "Max sequence length: 239\n",
      "Average sequence length: 119.26\n",
      "Percentage of sequences greater than average length: 49.47%\n",
      "Generated 30510 triplets\n",
      "Sample triplet:\n",
      "{\n",
      "  \"anchor\": \"no movement , no yuks , not much of anything .\",\n",
      "  \"positive\": [\n",
      "    \"a moving , if uneven , success .\",\n",
      "    \"two big things are missing -- anything approaching a visceral kick , and anything approaching even a vague reason to sit through it all .\"\n",
      "  ],\n",
      "  \"negatives\": [\n",
      "    [\n",
      "      \"darkly funny and frequently insightful .\",\n",
      "      \"... this story gets sillier , not scarier , as it goes along ...\"\n",
      "    ],\n",
      "    [\n",
      "      \"clint eastwood 's blood work is a lot like a well-made pb & j sandwich : familiar , fairly uneventful and boasting no real surprises -- but still quite tasty and inviting all the same .\",\n",
      "      \"reign of fire has the disadvantage of also looking cheap .\"\n",
      "    ],\n",
      "    [\n",
      "      \"not all of the stories work and the ones that do are thin and scattered , but the film works well enough to make it worth watching .\",\n",
      "      \"none of this so-called satire has any sting to it , as if woody is afraid of biting the hand that has finally , to some extent , warmed up to him .\"\n",
      "    ],\n",
      "    [\n",
      "      \"the riveting performances by the incredibly flexible cast make love a joy to behold .\",\n",
      "      \"gets the look and the period trappings right , but it otherwise drowns in a sea of visual and verbal clich\\u00e9s .\"\n",
      "    ],\n",
      "    [\n",
      "      \"whether or not ram dass proves as clear and reliable an authority on that as he was about inner consciousness , fierce grace reassures us that he will once again be an honest and loving one .\",\n",
      "      \"-lrb- breheny 's -rrb- lensing of the new zealand and cook island locations captures both the beauty of the land and the people .\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# Function to load the model and tokenizer\n",
    "def load_model_tokenizer(model_name, single_precision):\n",
    "    if model_name == 'meta-llama/llama-2-7b-hf':\n",
    "        if not single_precision:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        else:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    return model, tokenizer\n",
    "\n",
    "# Class to represent input examples\n",
    "class InputExample(object):\n",
    "    def __init__(self, guid=None, text_a=\"\", text_b=\"\", label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "# Class to process SST2 data\n",
    "class SST2Processor():\n",
    "    def __init__(self, classes_in_data):\n",
    "        self.labels = classes_in_data\n",
    "        self.label_mapping = {k: i for (i, k) in enumerate(self.labels)}\n",
    "\n",
    "    def get_examples(self, file_path):\n",
    "        examples = []\n",
    "        with open(file_path, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for idx, line in enumerate(lines):\n",
    "                linelist = line.strip().split('\\t')\n",
    "                text_a = linelist[0]\n",
    "                label = linelist[1]\n",
    "                guid = f\"{file_path}-{idx}\"\n",
    "                example = InputExample(guid=guid, text_a=text_a, label=self.label_mapping[label])\n",
    "                examples.append(example)\n",
    "        return examples\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(train_path, test_path, classes_in_data):\n",
    "    dataset_dict = dict()\n",
    "    processor = SST2Processor(classes_in_data)\n",
    "    dataset_dict['train'] = processor.get_examples(train_path)\n",
    "    dataset_dict['test'] = processor.get_examples(test_path)\n",
    "    print(\"Length of train set: \", len(dataset_dict['train']))\n",
    "    print(\"Length of test set\", len(dataset_dict['test']))\n",
    "    print(\"Train example at 0th index: \", dataset_dict['train'][0])\n",
    "    return dataset_dict\n",
    "\n",
    "# Function to create KDTree for nearest neighbor search\n",
    "def get_kdtree(dataset):\n",
    "    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    train_sentences = [ex.text_a for ex in dataset['train']]\n",
    "    train_embeddings = sbert_model.encode(train_sentences)\n",
    "    tree = KDTree(train_embeddings)\n",
    "    return sbert_model, tree\n",
    "\n",
    "# Function to get top k examples using KDTree\n",
    "def get_top_k_examples(test_example, sbert_model, tree, dataset_dict, k=10):\n",
    "    test_embedding = sbert_model.encode([test_example.text_a])\n",
    "    _, top_k_indices = tree.query(test_embedding, k=k)\n",
    "    top_k_examples = [dataset_dict['train'][idx] for idx in top_k_indices[0]]\n",
    "    return top_k_examples\n",
    "\n",
    "# Function to perform one-shot prediction\n",
    "def one_shot_prediction(test_example, one_shot_example, prompt_prefix, prompt_suffix, tokenizer, max_rem_len, prompts, model, class_idx, classes, device):\n",
    "    # Construct the prompt\n",
    "    prompt = f'{prompt_prefix}Review: {one_shot_example.text_a}\\nSentiment: {classes[one_shot_example.label]}\\n\\nReview: {test_example.text_a}\\n'\n",
    "    enc = tokenizer.encode_plus(prompt, return_tensors='pt', padding='longest')\n",
    "    \n",
    "    # Truncate and pad the input\n",
    "    for key, enc_value in list(enc.items()):\n",
    "        enc_value = enc_value[:, :max_rem_len]\n",
    "        enc[key] = torch.cat([enc_value, prompts[key][:enc_value.shape[0]]], dim=1)\n",
    "    \n",
    "    seq_len = enc['input_ids'].shape[1]\n",
    "    enc = {ky: v.to(device) for ky, v in enc.items()}\n",
    "    \n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        result = model(**enc).logits\n",
    "    \n",
    "    result = result[:, -1, class_idx]\n",
    "    result = F.softmax(result, dim=1)\n",
    "    preds = torch.argmax(result, dim=-1)\n",
    "    confidence = result[0][preds].item()\n",
    "    \n",
    "    return seq_len, test_example.label, preds.cpu().item(), confidence\n",
    "\n",
    "# Function to perform two-shot prediction\n",
    "def two_shot_prediction(test_example, one_shot_example1, one_shot_example2, prompt_prefix, prompt_suffix, tokenizer, max_rem_len, prompts, model, class_idx, classes, device):\n",
    "    # Construct the prompt\n",
    "    prompt = f'{prompt_prefix}Review: {one_shot_example1.text_a}\\nSentiment: {classes[one_shot_example1.label]}\\n\\n'\n",
    "    prompt += f'Review: {one_shot_example2.text_a}\\nSentiment: {classes[one_shot_example2.label]}\\n\\n'\n",
    "    prompt += f'Review: {test_example.text_a}\\n'\n",
    "    \n",
    "    enc = tokenizer.encode_plus(prompt, return_tensors='pt', padding='longest')\n",
    "    \n",
    "    # Truncate and pad the input\n",
    "    for key, enc_value in list(enc.items()):\n",
    "        enc_value = enc_value[:, :max_rem_len]\n",
    "        enc[key] = torch.cat([enc_value, prompts[key][:enc_value.shape[0]]], dim=1)\n",
    "    \n",
    "    seq_len = enc['input_ids'].shape[1]\n",
    "    enc = {ky: v.to(device) for ky, v in enc.items()}\n",
    "    \n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        result = model(**enc).logits\n",
    "    \n",
    "    result = result[:, -1, class_idx]\n",
    "    result = F.softmax(result, dim=1)\n",
    "    preds = torch.argmax(result, dim=-1)\n",
    "    confidence = result[0][preds].item()\n",
    "    \n",
    "    return seq_len, test_example.label, preds.cpu().item(), confidence\n",
    "\n",
    "# Function to process a batch of predictions\n",
    "def pred_batch(splt, prompt_prefix, prompt_suffix, tokenizer, indexes, dataset_dict, sbert_model, tree, max_rem_len, prompts, batch_size, model, class_idx, classes, device):\n",
    "    test_examples = [dataset_dict[splt][i] for i in indexes if i < len(dataset_dict[splt])]\n",
    "\n",
    "    all_preds_one_shot = []\n",
    "    all_labels_one_shot = []\n",
    "    results_one_shot = []\n",
    "    seq_lens_one_shot = []\n",
    "\n",
    "    all_preds_two_shot = []\n",
    "    all_labels_two_shot = []\n",
    "    results_two_shot = []\n",
    "    seq_lens_two_shot = []\n",
    "\n",
    "    for test_example in test_examples:\n",
    "        # Get top k similar examples\n",
    "        top_k_examples = get_top_k_examples(test_example, sbert_model, tree, dataset_dict, k=10)\n",
    "        \n",
    "        # One-shot predictions\n",
    "        for one_shot_example in top_k_examples:\n",
    "            seq_len, labels, preds, confidence = one_shot_prediction(\n",
    "                test_example, one_shot_example, prompt_prefix, prompt_suffix, tokenizer, max_rem_len, prompts, model, class_idx, classes, device\n",
    "            )\n",
    "            all_labels_one_shot.append(labels)\n",
    "            all_preds_one_shot.append(preds)\n",
    "            seq_lens_one_shot.append(seq_len)\n",
    "\n",
    "            results_one_shot.append({\n",
    "                'test_instance': test_example.text_a,\n",
    "                'one_shot_example': one_shot_example.text_a,\n",
    "                'prediction': preds,\n",
    "                'correct': 1 if preds == labels else 0,\n",
    "                'predicted_probability': confidence,\n",
    "                'sequence_length': seq_len\n",
    "            })\n",
    "        \n",
    "        # Two-shot predictions\n",
    "        for i in range(len(top_k_examples)):\n",
    "            for j in range(i+1, len(top_k_examples)):\n",
    "                one_shot_example1 = top_k_examples[i]\n",
    "                one_shot_example2 = top_k_examples[j]\n",
    "                seq_len, labels, preds, confidence = two_shot_prediction(\n",
    "                    test_example, one_shot_example1, one_shot_example2, prompt_prefix, prompt_suffix, tokenizer, max_rem_len, prompts, model, class_idx, classes, device\n",
    "                )\n",
    "                all_labels_two_shot.append(labels)\n",
    "                all_preds_two_shot.append(preds)\n",
    "                seq_lens_two_shot.append(seq_len)\n",
    "\n",
    "                results_two_shot.append({\n",
    "                    'test_instance': test_example.text_a,\n",
    "                    'one_shot_example1': one_shot_example1.text_a,\n",
    "                    'one_shot_example2': one_shot_example2.text_a,\n",
    "                    'prediction': preds,\n",
    "                    'correct': 1 if preds == labels else 0,\n",
    "                    'predicted_probability': confidence,\n",
    "                    'sequence_length': seq_len\n",
    "                })\n",
    "\n",
    "    return all_labels_one_shot, all_preds_one_shot, results_one_shot, all_labels_two_shot, all_preds_two_shot, results_two_shot, seq_lens_one_shot, seq_lens_two_shot\n",
    "\n",
    "# Function to calculate compatibility\n",
    "def calculate_compatibility(one_shot_results, two_shot_results):\n",
    "    compatibility_results = []\n",
    "    for two_shot in two_shot_results:\n",
    "        test_instance = two_shot['test_instance']\n",
    "        example1 = two_shot['one_shot_example1']\n",
    "        example2 = two_shot['one_shot_example2']\n",
    "        \n",
    "        # Find individual one-shot predictions\n",
    "        pred1 = next(r['correct'] for r in one_shot_results if r['test_instance'] == test_instance and r['one_shot_example'] == example1)\n",
    "        pred2 = next(r['correct'] for r in one_shot_results if r['test_instance'] == test_instance and r['one_shot_example'] == example2)\n",
    "        \n",
    "        # Calculate compatibility\n",
    "        compatibility = 1 if pred1 == 1 and pred2 == 1 and two_shot['correct'] == 1 else 0\n",
    "        \n",
    "        compatibility_results.append({\n",
    "            'test_instance': test_instance,\n",
    "            'example1': example1,\n",
    "            'example2': example2,\n",
    "            'pred1': pred1,\n",
    "            'pred2': pred2,\n",
    "            'pair_pred_AB': two_shot['correct'],\n",
    "            'compatibility': compatibility\n",
    "        })\n",
    "    \n",
    "    return compatibility_results\n",
    "\n",
    "# Function to generate triplets with multiple negatives\n",
    "def generate_triplets_with_multiple_negatives(compatibility_results, num_negatives=5):\n",
    "    triplets = []\n",
    "    \n",
    "    # Group compatibility results by test instance\n",
    "    grouped_results = {}\n",
    "    all_examples = set()\n",
    "    for comp in compatibility_results:\n",
    "        if comp['test_instance'] not in grouped_results:\n",
    "            grouped_results[comp['test_instance']] = {'compatible': [], 'incompatible': []}\n",
    "        \n",
    "        if comp['compatibility'] == 1:\n",
    "            grouped_results[comp['test_instance']]['compatible'].append((comp['example1'], comp['example2']))\n",
    "        else:\n",
    "            grouped_results[comp['test_instance']]['incompatible'].append((comp['example1'], comp['example2']))\n",
    "        \n",
    "        all_examples.add(comp['example1'])\n",
    "        all_examples.add(comp['example2'])\n",
    "    \n",
    "    all_examples = list(all_examples)\n",
    "\n",
    "    for test_instance, results in grouped_results.items():\n",
    "        for positive in results['compatible']:\n",
    "            negatives = []\n",
    "            \n",
    "            # First, try to get negatives from incompatible examples\n",
    "            negatives.extend(random.sample(results['incompatible'], min(num_negatives, len(results['incompatible']))))\n",
    "            \n",
    "            # If we don't have enough, add random examples from other queries\n",
    "            while len(negatives) < num_negatives:\n",
    "                random_example1 = random.choice(all_examples)\n",
    "                random_example2 = random.choice(all_examples)\n",
    "                if (random_example1, random_example2) not in results['compatible'] and (random_example1, random_example2) not in negatives:\n",
    "                    negatives.append((random_example1, random_example2))\n",
    "            \n",
    "            triplets.append({\n",
    "                'anchor': test_instance,\n",
    "                'positive': positive,\n",
    "                'negatives': negatives\n",
    "            })\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "def main():\n",
    "    # Configurations\n",
    "    dataset = 'sst2'\n",
    "    model_name = 'meta-llama/llama-2-7b-hf'\n",
    "    single_precision = True\n",
    "    gpu_id = 0\n",
    "    train_datapath = 'train.tsv'\n",
    "    test_datapath = 'test.tsv'\n",
    "    classes = ['negative', 'positive']\n",
    "    classes_in_data = ['0', '1']\n",
    "    prompt_prefix = 'Your task is to judge whether the sentiment of a movie review is positive or negative.\\n'\n",
    "    prompt_suffix = 'Sentiment: '\n",
    "    batch_size = 10\n",
    "    \n",
    "    # Seeds and device setup\n",
    "    random.seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "    device = torch.device('cuda:'+str(gpu_id) if torch.cuda.is_available() else 'cpu')\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = load_model_tokenizer(model_name, single_precision)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Get indices of class label words in the vocab\n",
    "    class_idx = tuple([tokenizer.encode(clas, add_special_tokens=False)[0] for clas in classes])\n",
    "\n",
    "    # Load dataset\n",
    "    dataset_dict = load_dataset(train_datapath, test_datapath, classes_in_data)\n",
    "\n",
    "    # Model for getting similar demonstrations\n",
    "    sbert_model, tree = get_kdtree(dataset_dict)\n",
    "\n",
    "    # Prepare prompts\n",
    "    prompts = tokenizer.batch_encode_plus([prompt_suffix for _ in range(batch_size)], return_tensors='pt', padding='longest', add_special_tokens=False)\n",
    "    max_rem_len = model.config.max_position_embeddings - prompts['input_ids'].shape[1]\n",
    "\n",
    "    all_preds_one_shot = list()\n",
    "    all_labels_one_shot = list()\n",
    "    all_results_one_shot = list()\n",
    "    all_seq_lens_one_shot = list()\n",
    "\n",
    "    all_preds_two_shot = list()\n",
    "    all_labels_two_shot = list()\n",
    "    all_results_two_shot = list()\n",
    "    all_seq_lens_two_shot = list()\n",
    "\n",
    "    num_examples = len(dataset_dict['test'])\n",
    "    for start_idx in tqdm(range(0, num_examples, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, num_examples)\n",
    "        indexes = range(start_idx, end_idx)\n",
    "        labels_one_shot, preds_one_shot, results_one_shot, labels_two_shot, preds_two_shot, results_two_shot, seq_lens_one_shot, seq_lens_two_shot = pred_batch(\n",
    "            'test', prompt_prefix, prompt_suffix, tokenizer, indexes, dataset_dict, sbert_model, tree, max_rem_len, prompts, batch_size, model, class_idx, classes, device\n",
    "        )\n",
    "        \n",
    "        all_preds_one_shot.extend(preds_one_shot)\n",
    "        all_labels_one_shot.extend(labels_one_shot)\n",
    "        all_results_one_shot.extend(results_one_shot)\n",
    "        all_seq_lens_one_shot.extend(seq_lens_one_shot)\n",
    "\n",
    "        all_preds_two_shot.extend(preds_two_shot)\n",
    "        all_labels_two_shot.extend(labels_two_shot)\n",
    "        all_results_two_shot.extend(results_two_shot)\n",
    "        all_seq_lens_two_shot.extend(seq_lens_two_shot)\n",
    "\n",
    "    # One-shot results\n",
    "    report_one_shot = classification_report(all_labels_one_shot, all_preds_one_shot, digits=4)\n",
    "    print('One-shot Classification Report:')\n",
    "    print(report_one_shot)\n",
    "\n",
    "    results_df_one_shot = pd.DataFrame(all_results_one_shot)\n",
    "    results_df_one_shot.to_csv('one_shot_results.csv', index=False)\n",
    "\n",
    "    # Two-shot results\n",
    "    report_two_shot = classification_report(all_labels_two_shot, all_preds_two_shot, digits=4)\n",
    "    print('Two-shot Classification Report:')\n",
    "    print(report_two_shot)\n",
    "\n",
    "    results_df_two_shot = pd.DataFrame(all_results_two_shot)\n",
    "    results_df_two_shot.to_csv('two_shot_results.csv', index=False)\n",
    "\n",
    "    # Calculate sequence length statistics\n",
    "    all_seq_lens = all_seq_lens_one_shot + all_seq_lens_two_shot\n",
    "    max_seq_len = max(all_seq_lens)\n",
    "    avg_seq_len = sum(all_seq_lens) / len(all_seq_lens)\n",
    "    percentage_greater_than_avg = sum(1 for x in all_seq_lens if x > avg_seq_len) / len(all_seq_lens) * 100\n",
    "\n",
    "    print(f\"Max sequence length: {max_seq_len}\")\n",
    "    print(f\"Average sequence length: {avg_seq_len:.2f}\")\n",
    "    print(f\"Percentage of sequences greater than average length: {percentage_greater_than_avg:.2f}%\")\n",
    "\n",
    "    # Calculate compatibility\n",
    "    compatibility_results = calculate_compatibility(all_results_one_shot, all_results_two_shot)\n",
    "\n",
    "    # Save compatibility results to a CSV file\n",
    "    compatibility_df = pd.DataFrame(compatibility_results)\n",
    "    compatibility_df.to_csv('compatibility_results.csv', index=False)\n",
    "    triplets = generate_triplets_with_multiple_negatives(compatibility_results, num_negatives=5)\n",
    "\n",
    "    print(f\"Generated {len(triplets)} triplets\")\n",
    "\n",
    "    # Save triplets to a JSON file\n",
    "    with open('triplets.json', 'w') as f:\n",
    "        json.dump(triplets, f)\n",
    "\n",
    "    # Print a sample triplet\n",
    "    if triplets:\n",
    "        print(\"Sample triplet:\")\n",
    "        print(json.dumps(triplets[0], indent=2))\n",
    "    else:\n",
    "        print(\"No triplets generated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bced4fc6-86ae-43a1-a431-16d95bf7ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('triplets.json', 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcb4e82-042c-40d0-8b68-daba32b07dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from datasets import Dataset\n",
    "\n",
    "from sentence_transformers import InputExample, LoggingHandler, SentenceTransformer, losses, models, util\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e373b8-5e45-476c-9d7a-c5ac142e46a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>positive1</th>\n",
       "      <th>positive2</th>\n",
       "      <th>negative1</th>\n",
       "      <th>negative2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>a moving , if uneven , success .</td>\n",
       "      <td>two big things are missing -- anything approac...</td>\n",
       "      <td>darkly funny and frequently insightful .</td>\n",
       "      <td>... this story gets sillier , not scarier , as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>a moving , if uneven , success .</td>\n",
       "      <td>two big things are missing -- anything approac...</td>\n",
       "      <td>clint eastwood 's blood work is a lot like a w...</td>\n",
       "      <td>reign of fire has the disadvantage of also loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>a moving , if uneven , success .</td>\n",
       "      <td>two big things are missing -- anything approac...</td>\n",
       "      <td>not all of the stories work and the ones that ...</td>\n",
       "      <td>none of this so-called satire has any sting to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>a moving , if uneven , success .</td>\n",
       "      <td>two big things are missing -- anything approac...</td>\n",
       "      <td>the riveting performances by the incredibly fl...</td>\n",
       "      <td>gets the look and the period trappings right ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>a moving , if uneven , success .</td>\n",
       "      <td>two big things are missing -- anything approac...</td>\n",
       "      <td>whether or not ram dass proves as clear and re...</td>\n",
       "      <td>-lrb- breheny 's -rrb- lensing of the new zeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152421</th>\n",
       "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
       "      <td>it 's never laugh-out-loud funny , but it is f...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>the problem with all of this : it 's not reall...</td>\n",
       "      <td>it 's mildly amusing , but i certainly ca n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152422</th>\n",
       "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
       "      <td>it 's never laugh-out-loud funny , but it is f...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>none of this is very original , and it is n't ...</td>\n",
       "      <td>and it 's not that funny -- which is just gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152423</th>\n",
       "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
       "      <td>it 's never laugh-out-loud funny , but it is f...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>but one thing 's for sure : it never comes clo...</td>\n",
       "      <td>it 's mildly amusing , but i certainly ca n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152424</th>\n",
       "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
       "      <td>it 's never laugh-out-loud funny , but it is f...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>less funny than it should be and less funny th...</td>\n",
       "      <td>it 's mildly amusing , but i certainly ca n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152425</th>\n",
       "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
       "      <td>it 's never laugh-out-loud funny , but it is f...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>it 's funny , as the old saying goes , because...</td>\n",
       "      <td>but one thing 's for sure : it never comes clo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152426 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   anchor  \\\n",
       "0          no movement , no yuks , not much of anything .   \n",
       "1          no movement , no yuks , not much of anything .   \n",
       "2          no movement , no yuks , not much of anything .   \n",
       "3          no movement , no yuks , not much of anything .   \n",
       "4          no movement , no yuks , not much of anything .   \n",
       "...                                                   ...   \n",
       "152421  but here 's the real damn : it is n't funny , ...   \n",
       "152422  but here 's the real damn : it is n't funny , ...   \n",
       "152423  but here 's the real damn : it is n't funny , ...   \n",
       "152424  but here 's the real damn : it is n't funny , ...   \n",
       "152425  but here 's the real damn : it is n't funny , ...   \n",
       "\n",
       "                                                positive1  \\\n",
       "0                        a moving , if uneven , success .   \n",
       "1                        a moving , if uneven , success .   \n",
       "2                        a moving , if uneven , success .   \n",
       "3                        a moving , if uneven , success .   \n",
       "4                        a moving , if uneven , success .   \n",
       "...                                                   ...   \n",
       "152421  it 's never laugh-out-loud funny , but it is f...   \n",
       "152422  it 's never laugh-out-loud funny , but it is f...   \n",
       "152423  it 's never laugh-out-loud funny , but it is f...   \n",
       "152424  it 's never laugh-out-loud funny , but it is f...   \n",
       "152425  it 's never laugh-out-loud funny , but it is f...   \n",
       "\n",
       "                                                positive2  \\\n",
       "0       two big things are missing -- anything approac...   \n",
       "1       two big things are missing -- anything approac...   \n",
       "2       two big things are missing -- anything approac...   \n",
       "3       two big things are missing -- anything approac...   \n",
       "4       two big things are missing -- anything approac...   \n",
       "...                                                   ...   \n",
       "152421  it 's funny , as the old saying goes , because...   \n",
       "152422  it 's funny , as the old saying goes , because...   \n",
       "152423  it 's funny , as the old saying goes , because...   \n",
       "152424  it 's funny , as the old saying goes , because...   \n",
       "152425  it 's funny , as the old saying goes , because...   \n",
       "\n",
       "                                                negative1  \\\n",
       "0                darkly funny and frequently insightful .   \n",
       "1       clint eastwood 's blood work is a lot like a w...   \n",
       "2       not all of the stories work and the ones that ...   \n",
       "3       the riveting performances by the incredibly fl...   \n",
       "4       whether or not ram dass proves as clear and re...   \n",
       "...                                                   ...   \n",
       "152421  the problem with all of this : it 's not reall...   \n",
       "152422  none of this is very original , and it is n't ...   \n",
       "152423  but one thing 's for sure : it never comes clo...   \n",
       "152424  less funny than it should be and less funny th...   \n",
       "152425  it 's funny , as the old saying goes , because...   \n",
       "\n",
       "                                                negative2  \n",
       "0       ... this story gets sillier , not scarier , as...  \n",
       "1       reign of fire has the disadvantage of also loo...  \n",
       "2       none of this so-called satire has any sting to...  \n",
       "3       gets the look and the period trappings right ,...  \n",
       "4       -lrb- breheny 's -rrb- lensing of the new zeal...  \n",
       "...                                                   ...  \n",
       "152421  it 's mildly amusing , but i certainly ca n't ...  \n",
       "152422  and it 's not that funny -- which is just gene...  \n",
       "152423  it 's mildly amusing , but i certainly ca n't ...  \n",
       "152424  it 's mildly amusing , but i certainly ca n't ...  \n",
       "152425  but one thing 's for sure : it never comes clo...  \n",
       "\n",
       "[152426 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data = data.explode('negatives')\n",
    "\n",
    "\n",
    "data[['positive1', 'positive2']]  = pd.DataFrame(data['positive'].tolist(), index= data.index)\n",
    "data[['negative1', 'negative2']] = pd.DataFrame(data['negatives'].tolist(), index= data.index)\n",
    "\n",
    "data = data.drop('positive', axis=1)\n",
    "data = data.drop('negatives', axis=1)\n",
    "data = data.drop_duplicates()\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f22970-4412-4219-8d97-207f70a7d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "max_seq_length = 300\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "max_passages = 0\n",
    "num_epochs = 10\n",
    "pooling = \"mean\"\n",
    "negs_to_use = None\n",
    "warmup_steps = 1000\n",
    "lr = 2e-5\n",
    "num_negs_per_system = 5\n",
    "use_pre_trained_model = False\n",
    "use_all_queries = False\n",
    "ce_score_margin = 3.0\n",
    "model_save_path = 'output/training_triplets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17b8647-fae5-41a7-a6c1-056217f20ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)\n",
    "model.max_seq_length = max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd74649-7348-4e6f-8330-f7bd773fba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23820' max='23820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23820/23820 36:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.623600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.313400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.282300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.248900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MSMARCODataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "      self.data = data.reset_index(drop=True)\n",
    "      self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "      row = self.data.iloc[item]\n",
    "      query = row.anchor\n",
    "      pos_text = row.positive1 + self.tokenizer.sep_token + row.positive2\n",
    "      neg_text = row.negative1 + self.tokenizer.sep_token + row.negative2\n",
    "      return InputExample(texts=[query, pos_text, neg_text])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "train_dataset = MSMARCODataset(data, model.tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    use_amp=True,\n",
    "    checkpoint_path=model_save_path,\n",
    "    checkpoint_save_steps=len(train_dataloader),\n",
    "    optimizer_params={\"lr\": lr},\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162dd663-f194-4071-9ba7-f00ebf019856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ishan/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044bd868b0a748798557590a501c692f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'prediction'], dtype='object')\n",
      "Encoding test reviews...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae54274909d48119d76a81f604c739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating KDTree for training data...\n",
      "Processing test examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1821 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 1821/1821 [05:04<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing completed. Results saved to 'test_results_with_predictions.csv'\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.59      0.71       912\n",
      "    positive       0.69      0.91      0.79       909\n",
      "\n",
      "    accuracy                           0.75      1821\n",
      "   macro avg       0.78      0.75      0.75      1821\n",
      "weighted avg       0.78      0.75      0.75      1821\n",
      "\n",
      "\n",
      "Top 5 most compatible pairs:\n",
      "                                                  query  \\\n",
      "1450                                     what 's next ?   \n",
      "152                                               no. .   \n",
      "234       a smart , sweet and playful romantic comedy .   \n",
      "1551  an instant candidate for worst movie of the ye...   \n",
      "874                                a very funny movie .   \n",
      "\n",
      "                                          top_example_1  \\\n",
      "1450                                     what 's next ?   \n",
      "152                                               no. .   \n",
      "234   a smart , sassy and exceptionally charming rom...   \n",
      "1551                       the worst film of the year .   \n",
      "874                                      a funny film .   \n",
      "\n",
      "                              top_example_2  compatibility_score  \\\n",
      "1450                         what 's next ?             1.000000   \n",
      "152                        absolutely not .             0.878917   \n",
      "234     a witty , low-key romantic comedy .             0.866258   \n",
      "1551  one of the worst movies of the year .             0.863705   \n",
      "874            a surprisingly funny movie .             0.855423   \n",
      "\n",
      "      two_shot_prediction  confidence  \n",
      "1450                    1    0.517571  \n",
      "152                     1    0.590779  \n",
      "234                     1    0.637031  \n",
      "1551                    1    0.564098  \n",
      "874                     1    0.600188  \n",
      "\n",
      "Bottom 5 least compatible pairs:\n",
      "                                                  query  \\\n",
      "910              ecks this one off your must-see list .   \n",
      "1681  a distant , even sterile , yet compulsively wa...   \n",
      "836   ... breathes surprising new life into the fami...   \n",
      "1503  a sweet-natured reconsideration of one of san ...   \n",
      "907      has the feel of an unedited personal journal .   \n",
      "\n",
      "                                          top_example_1  \\\n",
      "910   ... it 's as comprehensible as any dummies gui...   \n",
      "1681  a compassionate , moving portrait of an americ...   \n",
      "836   problem is , we have no idea what in creation ...   \n",
      "1503  this charming , thought-provoking new york fes...   \n",
      "907   director paul cox 's unorthodox , abstract app...   \n",
      "\n",
      "                                          top_example_2  compatibility_score  \\\n",
      "910                        beware the quirky brit-com .             0.295208   \n",
      "1681  so aggressively cheery that pollyana would rea...             0.306732   \n",
      "836                   familiar but utterly delightful .             0.308927   \n",
      "1503  debut effort by `` project greenlight '' winne...             0.313282   \n",
      "907   journalistically dubious , inept and often let...             0.322364   \n",
      "\n",
      "      two_shot_prediction  confidence  \n",
      "910                     1    0.562177  \n",
      "1681                    1    0.563138  \n",
      "836                     1    0.537041  \n",
      "1503                    1    0.683420  \n",
      "907                     1    0.557364  \n",
      "\n",
      "Average compatibility score: 0.5240\n",
      "Average confidence: 0.5924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.spatial import KDTree\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to create KDTree from training dataset\n",
    "def get_kdtree(dataset):\n",
    "    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    train_sentences = dataset['review'].tolist()\n",
    "    train_embeddings = sbert_model.encode(train_sentences)\n",
    "    tree = KDTree(train_embeddings)\n",
    "    return sbert_model, tree, train_embeddings\n",
    "\n",
    "# Load the trained SentenceTransformer model\n",
    "sentence_model = SentenceTransformer('output/training_triplets')\n",
    "\n",
    "# Load the LLaMA-2 model for two-shot prediction\n",
    "llama_model_name = 'meta-llama/llama-2-7b-hf'\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_name, torch_dtype=torch.float16)\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "llama_tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "llama_model.resize_token_embeddings(len(llama_tokenizer))\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id\n",
    "llama_model.to('cuda')\n",
    "llama_model.eval()\n",
    "\n",
    "# Define the column names\n",
    "column_names = ['review', 'prediction']\n",
    "\n",
    "# Load the training data and test data with specified column names\n",
    "train_data = pd.read_csv('train.tsv', sep='\\t', names=column_names)\n",
    "test_data = pd.read_csv('test.tsv', sep='\\t', names=column_names)\n",
    "\n",
    "# Check the columns of the DataFrame\n",
    "print(test_data.columns)\n",
    "\n",
    "# Function to generate all possible pairs\n",
    "def generate_pairs(neighbors):\n",
    "    return list(combinations(neighbors, 2))\n",
    "\n",
    "# Function to predict compatibility scores\n",
    "def predict_compatibility(model, query, pair):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    pair_embeddings = model.encode(pair, convert_to_tensor=True)\n",
    "    cos_sim = util.pytorch_cos_sim(query_embedding, pair_embeddings)\n",
    "    return cos_sim.mean().item()\n",
    "\n",
    "# Function for two-shot prediction  \n",
    "def two_shot_prediction(test_example, example1, example2, prompt_prefix, prompt_suffix, tokenizer, model, class_idx, classes):\n",
    "    prompt = f'{prompt_prefix}Review: {example1}\\nSentiment: {classes[0]}\\n\\n'\n",
    "    prompt += f'Review: {example2}\\nSentiment: {classes[1]}\\n\\n'\n",
    "    prompt += f'Review: {test_example}\\n'\n",
    "    \n",
    "    enc = tokenizer.encode_plus(prompt, return_tensors='pt', padding='longest')\n",
    "    enc = {k: v.to('cuda') for k, v in enc.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = model(**enc).logits\n",
    "    \n",
    "    result = result[:, -1, class_idx]\n",
    "    result = F.softmax(result, dim=1)\n",
    "    pred = torch.argmax(result, dim=-1)\n",
    "    confidence = result[0][pred].item()\n",
    "    \n",
    "    return pred.cpu().item(), confidence\n",
    "\n",
    "# Main testing process\n",
    "def test_model(test_data, train_data, sentence_model, llama_model, llama_tokenizer, k=5):\n",
    "    results = []\n",
    "    \n",
    "    print(\"Encoding test reviews...\")\n",
    "    test_embeddings = sentence_model.encode(test_data['review'].tolist(), show_progress_bar=True)\n",
    "    \n",
    "    print(\"Creating KDTree for training data...\")\n",
    "    train_sbert_model, kd_tree, train_embeddings = get_kdtree(train_data)\n",
    "    \n",
    "    prompt_prefix = 'Your task is to judge whether the sentiment of a movie review is positive or negative.\\n'\n",
    "    prompt_suffix = 'Sentiment: '\n",
    "    classes = ['negative', 'positive']\n",
    "    class_idx = tuple([llama_tokenizer.encode(clas, add_special_tokens=False)[0] for clas in classes])\n",
    "    \n",
    "    print(\"Processing test examples...\")\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        query = row['review']\n",
    "        query_embedding = sentence_model.encode(query)\n",
    "        _, neighbor_indices = kd_tree.query(query_embedding, k=k)\n",
    "        neighbors = train_data.iloc[neighbor_indices]['review'].tolist()\n",
    "        \n",
    "        pairs = generate_pairs(neighbors)\n",
    "        scores = []\n",
    "        for pair in pairs:\n",
    "            score = predict_compatibility(sentence_model, query, list(pair))\n",
    "            scores.append((pair, score))\n",
    "        \n",
    "        sorted_pairs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        top_pair, top_score = sorted_pairs[0]\n",
    "        \n",
    "        pred, confidence = two_shot_prediction(\n",
    "    query, \n",
    "    top_pair[0], \n",
    "    top_pair[1],\n",
    "    prompt_prefix, \n",
    "    prompt_suffix, \n",
    "    llama_tokenizer, \n",
    "    llama_model, \n",
    "    class_idx, \n",
    "    classes\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'original_prediction': row['prediction'],\n",
    "            'top_example_1': top_pair[0],\n",
    "            'top_example_2': top_pair[1],\n",
    "            'compatibility_score': top_score,\n",
    "            'two_shot_prediction': pred,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(int(row['prediction']))\n",
    "    \n",
    "    return pd.DataFrame(results), all_preds, all_labels\n",
    "\n",
    "# Run the testing process\n",
    "results_df, all_preds, all_labels = test_model(test_data, train_data, sentence_model, llama_model, llama_tokenizer)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('test_results_with_predictions.csv', index=False)\n",
    "print(\"Testing completed. Results saved to 'test_results_with_predictions.csv'\")\n",
    "\n",
    "# Generate and print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['negative', 'positive']))\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nTop 5 most compatible pairs:\")\n",
    "print(results_df.nlargest(5, 'compatibility_score')[['query', 'top_example_1', 'top_example_2', 'compatibility_score', 'two_shot_prediction', 'confidence']])\n",
    "\n",
    "print(\"\\nBottom 5 least compatible pairs:\")\n",
    "print(results_df.nsmallest(5, 'compatibility_score')[['query', 'top_example_1', 'top_example_2', 'compatibility_score', 'two_shot_prediction', 'confidence']])\n",
    "\n",
    "print(f\"\\nAverage compatibility score: {results_df['compatibility_score'].mean():.4f}\")\n",
    "print(f\"Average confidence: {results_df['confidence'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bcafc5-b46c-466a-b516-3b792c57c82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27aac6e03134092be6448ad92896f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'prediction'], dtype='object')\n",
      "Running our method...\n",
      "Encoding test reviews...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268acbcb1425452bbcca4b4140208aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating KDTree for training data...\n",
      "Processing test examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [05:17<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline method...\n",
      "Processing test examples (Baseline)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [01:28<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Our Method):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.59      0.70       912\n",
      "    positive       0.69      0.91      0.78       909\n",
      "\n",
      "    accuracy                           0.75      1821\n",
      "   macro avg       0.78      0.75      0.74      1821\n",
      "weighted avg       0.78      0.75      0.74      1821\n",
      "\n",
      "\n",
      "Classification Report (Baseline):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55       912\n",
      "    positive       0.60      0.90      0.72       909\n",
      "\n",
      "    accuracy                           0.66      1821\n",
      "   macro avg       0.70      0.66      0.63      1821\n",
      "weighted avg       0.70      0.66      0.63      1821\n",
      "\n",
      "\n",
      "Accuracy (Our Method): 0.7501\n",
      "Accuracy (Baseline): 0.6557\n",
      "\n",
      "Our Method - Top 5 most compatible pairs:\n",
      "                     query   top_example_1                      top_example_2  \\\n",
      "1450        what 's next ?  what 's next ?                     what 's next ?   \n",
      "152                  no. .           no. .                              yes .   \n",
      "151           ridiculous .      horrible .                       disgusting .   \n",
      "641          brilliant ! '     fantastic !                          amazing !   \n",
      "874   a very funny movie .  a funny film .  a very charming and funny movie .   \n",
      "\n",
      "      compatibility_score  two_shot_prediction  confidence  \n",
      "1450             1.000000                    1    0.558327  \n",
      "152              0.914780                    0    0.514644  \n",
      "151              0.858281                    1    0.729520  \n",
      "641              0.818603                    1    0.625209  \n",
      "874              0.805629                    0    0.531209  \n",
      "\n",
      "Our Method - Average compatibility score: 0.5591\n",
      "Our Method - Average confidence: 0.6259\n",
      "Baseline - Average confidence: 0.6165\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.spatial import KDTree\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to create KDTree from training dataset\n",
    "def get_kdtree(dataset):\n",
    "    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    train_sentences = dataset['review'].tolist()\n",
    "    train_embeddings = sbert_model.encode(train_sentences)\n",
    "    tree = KDTree(train_embeddings)\n",
    "    return sbert_model, tree, train_embeddings\n",
    "\n",
    "# Load the trained SentenceTransformer model\n",
    "sentence_model = SentenceTransformer('output/training_triplets')\n",
    "\n",
    "# Load the LLaMA-2 model for two-shot prediction\n",
    "llama_model_name = 'meta-llama/llama-2-7b-hf'\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_name, torch_dtype=torch.float16)\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "llama_tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "llama_model.resize_token_embeddings(len(llama_tokenizer))\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id\n",
    "llama_model.to('cuda')\n",
    "llama_model.eval()\n",
    "\n",
    "# Define the column names\n",
    "column_names = ['review', 'prediction']\n",
    "\n",
    "# Load the training data and test data with specified column names\n",
    "train_data = pd.read_csv('train.tsv', sep='\\t', names=column_names)\n",
    "test_data = pd.read_csv('test.tsv', sep='\\t', names=column_names)\n",
    "\n",
    "# Check the columns of the DataFrame\n",
    "print(test_data.columns)\n",
    "\n",
    "# Function to generate all possible pairs\n",
    "def generate_pairs(neighbors):\n",
    "    return list(combinations(neighbors, 2))\n",
    "\n",
    "# Function to predict compatibility scores\n",
    "def predict_compatibility(model, query, pair):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    pair_embeddings = model.encode(pair, convert_to_tensor=True)\n",
    "    cos_sim = util.pytorch_cos_sim(query_embedding, pair_embeddings)\n",
    "    return cos_sim.mean().item()\n",
    "\n",
    "# Function for two-shot prediction  \n",
    "def two_shot_prediction(test_example, example1, sentiment1, example2, sentiment2, prompt_prefix, prompt_suffix, tokenizer, model, class_idx, classes):\n",
    "    prompt = f'{prompt_prefix}Review: {example1}\\nSentiment: {sentiment1}\\n\\n'\n",
    "    prompt += f'Review: {example2}\\nSentiment: {sentiment2}\\n\\n'\n",
    "    prompt += f'Review: {test_example}\\n'\n",
    "    \n",
    "    enc = tokenizer.encode_plus(prompt, return_tensors='pt', padding='longest')\n",
    "    enc = {k: v.to('cuda') for k, v in enc.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = model(**enc).logits\n",
    "    \n",
    "    result = result[:, -1, class_idx]\n",
    "    result = F.softmax(result, dim=1)\n",
    "    pred = torch.argmax(result, dim=-1)\n",
    "    confidence = result[0][pred].item()\n",
    "    \n",
    "    return pred.cpu().item(), confidence\n",
    "\n",
    "def test_model_our_method(test_data, train_data, sentence_model, llama_model, llama_tokenizer, k=5):\n",
    "    results = []\n",
    "    \n",
    "    print(\"Encoding test reviews...\")\n",
    "    test_embeddings = sentence_model.encode(test_data['review'].tolist(), show_progress_bar=True)\n",
    "    \n",
    "    print(\"Creating KDTree for training data...\")\n",
    "    train_sbert_model, kd_tree, train_embeddings = get_kdtree(train_data)\n",
    "    \n",
    "    prompt_prefix = 'Your task is to judge whether the sentiment of a movie review is positive or negative.\\n'\n",
    "    prompt_suffix = 'Sentiment: '\n",
    "    classes = ['negative', 'positive']\n",
    "    class_idx = tuple([llama_tokenizer.encode(clas, add_special_tokens=False)[0] for clas in classes])\n",
    "    \n",
    "    print(\"Processing test examples...\")\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        query = row['review']\n",
    "        query_embedding = sentence_model.encode(query)\n",
    "        _, neighbor_indices = kd_tree.query(query_embedding, k=k)\n",
    "        neighbors = train_data.iloc[neighbor_indices]['review'].tolist()\n",
    "        \n",
    "        pairs = generate_pairs(neighbors)\n",
    "        scores = []\n",
    "        for pair in pairs:\n",
    "            score = predict_compatibility(sentence_model, query, list(pair))\n",
    "            scores.append((pair, score))\n",
    "        \n",
    "        sorted_pairs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        top_pair, top_score = sorted_pairs[0]\n",
    "        \n",
    "        sentiment1 = train_data.loc[train_data['review'] == top_pair[0], 'prediction'].iloc[0]\n",
    "        sentiment2 = train_data.loc[train_data['review'] == top_pair[1], 'prediction'].iloc[0]\n",
    "        \n",
    "        pred, confidence = two_shot_prediction(\n",
    "    query, \n",
    "    top_pair[0], train_data.loc[train_data['review'] == top_pair[0], 'prediction'].iloc[0],\n",
    "    top_pair[1], train_data.loc[train_data['review'] == top_pair[1], 'prediction'].iloc[0],\n",
    "    prompt_prefix, \n",
    "    prompt_suffix, \n",
    "    llama_tokenizer, \n",
    "    llama_model, \n",
    "    class_idx, \n",
    "    classes\n",
    ")\n",
    "        \n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'original_prediction': row['prediction'],\n",
    "            'top_example_1': top_pair[0],\n",
    "            'top_example_2': top_pair[1],\n",
    "            'compatibility_score': top_score,\n",
    "            'two_shot_prediction': pred,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(int(row['prediction']))\n",
    "    \n",
    "    return pd.DataFrame(results), all_preds, all_labels\n",
    "\n",
    "# Baseline method: random selection of examples\n",
    "def test_model_baseline(test_data, train_data, llama_model, llama_tokenizer):\n",
    "    results = []\n",
    "    \n",
    "    prompt_prefix = 'Your task is to judge whether the sentiment of a movie review is positive or negative.\\n'\n",
    "    prompt_suffix = 'Sentiment: '\n",
    "    classes = ['negative', 'positive']\n",
    "    class_idx = tuple([llama_tokenizer.encode(clas, add_special_tokens=False)[0] for clas in classes])\n",
    "    \n",
    "    print(\"Processing test examples (Baseline)...\")\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        query = row['review']\n",
    "        \n",
    "        # Randomly select two examples from the training set\n",
    "        random_examples = train_data.sample(n=2)\n",
    "        example1, sentiment1 = random_examples.iloc[0]['review'], random_examples.iloc[0]['prediction']\n",
    "        example2, sentiment2 = random_examples.iloc[1]['review'], random_examples.iloc[1]['prediction']\n",
    "        \n",
    "        pred, confidence = two_shot_prediction(\n",
    "            query, \n",
    "            example1, sentiment1,\n",
    "            example2, sentiment2,\n",
    "            prompt_prefix, \n",
    "            prompt_suffix, \n",
    "            llama_tokenizer, \n",
    "            llama_model, \n",
    "            class_idx, \n",
    "            classes\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'original_prediction': row['prediction'],\n",
    "            'random_example_1': example1,\n",
    "            'random_example_2': example2,\n",
    "            'two_shot_prediction': pred,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(int(row['prediction']))\n",
    "    \n",
    "    return pd.DataFrame(results), all_preds, all_labels\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data, models, etc. (as in the previous code)\n",
    "    \n",
    "    # Run our method\n",
    "    print(\"Running our method...\")\n",
    "    results_df_our, all_preds_our, all_labels_our = test_model_our_method(test_data, train_data, sentence_model, llama_model, llama_tokenizer)\n",
    "    \n",
    "    # Run baseline method\n",
    "    print(\"Running baseline method...\")\n",
    "    results_df_baseline, all_preds_baseline, all_labels_baseline = test_model_baseline(test_data, train_data, llama_model, llama_tokenizer)\n",
    "    \n",
    "    # Save results\n",
    "    results_df_our.to_csv('test_results_our_method.csv', index=False)\n",
    "    results_df_baseline.to_csv('test_results_baseline.csv', index=False)\n",
    "    \n",
    "    # Generate and print classification reports\n",
    "    print(\"\\nClassification Report (Our Method):\")\n",
    "    report_our = classification_report(all_labels_our, all_preds_our, target_names=['negative', 'positive'])\n",
    "    print(report_our)\n",
    "    \n",
    "    print(\"\\nClassification Report (Baseline):\")\n",
    "    report_baseline = classification_report(all_labels_baseline, all_preds_baseline, target_names=['negative', 'positive'])\n",
    "    print(report_baseline)\n",
    "    \n",
    "    # Calculate and print accuracies\n",
    "    accuracy_our = sum(p == l for p, l in zip(all_preds_our, all_labels_our)) / len(all_labels_our)\n",
    "    accuracy_baseline = sum(p == l for p, l in zip(all_preds_baseline, all_labels_baseline)) / len(all_labels_baseline)\n",
    "    \n",
    "    print(f\"\\nAccuracy (Our Method): {accuracy_our:.4f}\")\n",
    "    print(f\"Accuracy (Baseline): {accuracy_baseline:.4f}\")\n",
    "    \n",
    "    # Print some statistics for our method\n",
    "    print(\"\\nOur Method - Top 5 most compatible pairs:\")\n",
    "    print(results_df_our.nlargest(5, 'compatibility_score')[['query', 'top_example_1', 'top_example_2', 'compatibility_score', 'two_shot_prediction', 'confidence']])\n",
    "    \n",
    "    print(f\"\\nOur Method - Average compatibility score: {results_df_our['compatibility_score'].mean():.4f}\")\n",
    "    print(f\"Our Method - Average confidence: {results_df_our['confidence'].mean():.4f}\")\n",
    "    print(f\"Baseline - Average confidence: {results_df_baseline['confidence'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a63d5f-460d-414c-925d-97268e58538c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ishan]",
   "language": "python",
   "name": "conda-env-ishan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
